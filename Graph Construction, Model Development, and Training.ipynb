{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import classification_report\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx, to_networkx\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path).drop(columns='id')\n",
    "    X, y = df.drop(columns='target'), df['target']\n",
    "    return X, y\n",
    "\n",
    "train_X, train_y = load_data('Train_selected_features.csv')\n",
    "val1_X, val1_y = load_data('Val1_selected_features.csv')\n",
    "val2_X, val2_y = load_data('Val2_selected_features.csv')\n",
    "\n",
    "# Graph construction\n",
    "def build_graph(features, targets, threshold=0.95):\n",
    "    sim_matrix = cosine_similarity(features)\n",
    "    edges = np.argwhere(sim_matrix > threshold)\n",
    "    edges = edges[edges[:, 0] != edges[:, 1]]\n",
    "    G = nx.Graph()\n",
    "    for i in range(len(targets)):\n",
    "        G.add_node(i, feature=features.iloc[i].values, target=int(targets.iloc[i]))\n",
    "    for edge in edges:\n",
    "        G.add_edge(edge[0], edge[1], weight=sim_matrix[edge[0], edge[1]])\n",
    "    return G\n",
    "\n",
    "def to_pyg_data(G):\n",
    "    data = from_networkx(G)\n",
    "    data.x = torch.tensor([G.nodes[i]['feature'] for i in G.nodes()], dtype=torch.float)\n",
    "    data.y = torch.tensor([G.nodes[i]['target'] for i in G.nodes()], dtype=torch.long)\n",
    "    data.edge_attr = data.edge_attr if 'edge_attr' in data else None\n",
    "    data.train_mask = torch.ones(data.num_nodes, dtype=torch.bool)  # Full supervision\n",
    "    return data.to(device)\n",
    "\n",
    "Train_data = to_pyg_data(build_graph(train_X, train_y))\n",
    "Val1_data = to_pyg_data(build_graph(val1_X, val1_y))\n",
    "Val2_data = to_pyg_data(build_graph(val2_X, val2_y))\n",
    "\n",
    "# GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim, out_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_dim, out_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_weight))\n",
    "        return self.fc(x)\n",
    "\n",
    "# Initialize model\n",
    "model = GCN(Train_data.x.shape[1], hidden_dim=256, out_classes=Train_data.y.max().item() + 1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Early stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0.01):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = float('inf')\n",
    "        self.counter = 0\n",
    "        self.should_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_score - self.delta:\n",
    "            self.best_score = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.should_stop = True\n",
    "\n",
    "early_stopper = EarlyStopping()\n",
    "\n",
    "# Training loop\n",
    "def evaluate(data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index, data.edge_attr)\n",
    "        loss = F.cross_entropy(logits[data.train_mask], data.y[data.train_mask])\n",
    "        preds = logits.argmax(dim=1)\n",
    "        acc = (preds[data.train_mask] == data.y[data.train_mask]).float().mean().item()\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "    return loss.item(), acc, preds[data.train_mask], probs[data.train_mask]\n",
    "\n",
    "train_losses, val1_losses, val2_losses = [], [], []\n",
    "train_accs, val1_accs, val2_accs = [], [], []\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(Train_data.x, Train_data.edge_index, Train_data.edge_attr)\n",
    "    loss = F.cross_entropy(out[Train_data.train_mask], Train_data.y[Train_data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    tr_loss, tr_acc, tr_pred, tr_probs = evaluate(Train_data)\n",
    "    v1_loss, v1_acc, v1_pred, v1_probs = evaluate(Val1_data)\n",
    "    v2_loss, v2_acc, v2_pred, v2_probs = evaluate(Val2_data)\n",
    "\n",
    "    train_losses.append(tr_loss)\n",
    "    val1_losses.append(v1_loss)\n",
    "    val2_losses.append(v2_loss)\n",
    "\n",
    "    train_accs.append(tr_acc)\n",
    "    val1_accs.append(v1_acc)\n",
    "    val2_accs.append(v2_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={tr_loss:.4f}, Val1 Loss={v1_loss:.4f}, Val2 Loss={v2_loss:.4f}\")\n",
    "    early_stopper(v1_loss)\n",
    "    if early_stopper.should_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'GCN_model_final.pth')\n",
    "\n",
    "# Save predictions and probabilities\n",
    "def save_outputs(filename_prefix, preds, probs):\n",
    "    df = pd.DataFrame()\n",
    "    df['predictions'] = preds.cpu().numpy()\n",
    "    prob_df = pd.DataFrame(probs.cpu().numpy(), columns=[f'class_{i}' for i in range(probs.shape[1])])\n",
    "    df = pd.concat([df, prob_df], axis=1)\n",
    "    df.to_csv(f'{filename_prefix}_outputs.csv', index=False)\n",
    "\n",
    "save_outputs(\"Train\", tr_pred, tr_probs)\n",
    "save_outputs(\"Val1\", v1_pred, v1_probs)\n",
    "save_outputs(\"Val2\", v2_pred, v2_probs)\n",
    "\n",
    "# Save classification report\n",
    "def save_report(data, preds, name):\n",
    "    report = classification_report(data.y[data.train_mask].cpu(), preds.cpu(), output_dict=True)\n",
    "    pd.DataFrame(report).transpose().to_csv(f\"{name}_classification_report.csv\")\n",
    "\n",
    "save_report(Train_data, tr_pred, \"Train\")\n",
    "save_report(Val1_data, v1_pred, \"Val1\")\n",
    "save_report(Val2_data, v2_pred, \"Val2\")\n",
    "\n",
    "# Plot losses and accuracies\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val1_losses, label=\"Val1 Loss\")\n",
    "plt.plot(val2_losses, label=\"Val2 Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.savefig(\"loss_curves.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_accs, label=\"Train Acc\")\n",
    "plt.plot(val1_accs, label=\"Val1 Acc\")\n",
    "plt.plot(val2_accs, label=\"Val2 Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy Curves\")\n",
    "plt.savefig(\"accuracy_curves.png\")\n",
    "plt.close()\n",
    "\n",
    "# Save Graph Visualizations (Only Connected Nodes)\n",
    "def save_graph_image(pyg_data, name):\n",
    "    G = to_networkx(pyg_data, to_undirected=True)\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))  # Remove disconnected nodes\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "    y = pyg_data.y.cpu().numpy()\n",
    "    node_colors = [y[n] for n in G.nodes()]\n",
    "    cmap = plt.cm.Set3\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    nx.draw(G, pos,\n",
    "            node_color=node_colors,\n",
    "            cmap=cmap,\n",
    "            node_size=60,\n",
    "            edge_color='gray',\n",
    "            alpha=0.8,\n",
    "            with_labels=False)\n",
    "    plt.title(f\"{name} Graph (Connected Nodes Only)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{name}_graph.png\")\n",
    "    plt.close()\n",
    "\n",
    "save_graph_image(Train_data, \"Train\")\n",
    "save_graph_image(Val1_data, \"Val1\")\n",
    "save_graph_image(Val2_data, \"Val2\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
